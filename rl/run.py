import rl.prehandle
import numpy as np
from datetime import datetime
from rl.environment import SimpleStockEnv
from database.influx_manager import InfluxDBManager, InfluxDBConfig, InfluxDBCallbacks
from config import *
from stable_baselines3 import SAC
import os
from stable_baselines3.common.callbacks import CheckpointCallback, CallbackList
from stable_baselines3.common.callbacks import BaseCallback
from stable_baselines3.common.utils import set_random_seed
from stable_baselines3.common.vec_env import SubprocVecEnv, VecMonitor
import pickle
import glob

class TensorboardCallback(BaseCallback):
    def __init__(self, verbose=0):
        super(TensorboardCallback, self).__init__(verbose)

    def _on_step(self) -> bool:
        # è·å–å½“å‰ step çš„ info å­—å…¸
        # self.locals['infos'] æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå› ä¸ºå¯èƒ½æœ‰å¤šä¸ªå¹¶è¡Œç¯å¢ƒ
        info = self.locals['infos'][0]
        if "net_worth" in info:
            # å°†èµ„äº§å‡€å€¼è®°å½•åˆ° TensorBoard çš„ "Custom/NetWorth" è·¯å¾„ä¸‹
            self.logger.record("custom/net_worth", info["net_worth"])
        return True
    
def get_data_with_cache(manager, codes, start_date, end_date, cache_name="stock_data_cache.pkl"):
    # æ£€æŸ¥æœ¬åœ°æ˜¯å¦å­˜åœ¨ç¼“å­˜æ–‡ä»¶
    if os.path.exists(cache_name):
        print(f"ğŸ“¦ å‘ç°æœ¬åœ°ç¼“å­˜ {cache_name}ï¼Œæ­£åœ¨å¿«é€ŸåŠ è½½...")
        with open(cache_name, "rb") as f:
            return pickle.load(f)
    
    # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œåˆ™æ‰§è¡ŒåŸæœ‰çš„ä¸‹è½½é€»è¾‘
    print("ğŸš€ æœ¬åœ°æ— ç¼“å­˜ï¼Œå¼€å§‹ä» InfluxDB æå–æ•°æ®...")
    df_list = []
    for code in codes:
        try:
            df_temp = manager.get_stock_data_by_range(
                stock_code=code,
                start_time=start_date, 
                end_time=end_date
            )
            df_clean = rl.prehandle.preprocess_data(df_temp)
            if df_clean is not None and len(df_clean) > WINDOW_SIZE + TRAINING_DAYS:
                df_list.append(df_clean)
                print(f"âœ… {code} åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ {code} åŠ è½½å¤±è´¥: {e}")
    
    # ä¸‹è½½å®Œæˆåï¼Œä¿å­˜åˆ°æœ¬åœ°
    if df_list:
        print(f"ğŸ’¾ æ­£åœ¨å°† {len(df_list)} åªè‚¡ç¥¨ä¿å­˜è‡³æœ¬åœ°ç¼“å­˜...")
        with open(cache_name, "wb") as f:
            pickle.dump(df_list, f)
            
    return df_list

# å®šä¹‰æ—¶é—´èŒƒå›´
train_range = (datetime(2010, 1, 1), datetime(2021, 12, 31))
val_range   = (datetime(2022, 1, 1), datetime(2023, 12, 31))
test_range  = (datetime(2024, 1, 1), datetime(2025, 12, 31))

SEED = 215450649
np.random.seed(SEED)

MODEL_PATH = "sac_random_stock_model_1000.zip"
LOG_DIR = "./tensorboard_logs/"

def make_env(df_list, rank, seed=0):
    def _init():
        # è¿™é‡Œç¡®ä¿å¼•ç”¨ä½ å®šä¹‰çš„ SimpleStockEnv
        env = SimpleStockEnv(df_list)
        env.reset(seed=seed + rank)
        return env
    set_random_seed(seed)
    return _init

if __name__ == "__main__":
    np.random.seed(SEED) 
    
    # 1. åˆå§‹åŒ– InfluxDB
    config = InfluxDBConfig(HOST, DATABASE, TOKEN)
    manager = InfluxDBManager(config, InfluxDBCallbacks())
    
    # 2. è·å–è‚¡ç¥¨åˆ—è¡¨å¹¶éšæœºç­›é€‰
    all_stock_codes = manager.get_stock_code_list_by_date(target_date=datetime(2025, 12, 12))
    random_selected_codes = np.random.choice(all_stock_codes, size=1200, replace=False)

    # 3. é€šè¿‡ç¼“å­˜è·å–æ•°æ®
    # æ³¨æ„ï¼šå¦‚æœä½ æ›´æ”¹äº† train_rangeï¼Œè®°å¾—æ‰‹åŠ¨åˆ é™¤æ—§çš„ .pkl æ–‡ä»¶
    df_list = get_data_with_cache(
        manager, 
        random_selected_codes, 
        train_range[0], 
        train_range[1],
        cache_name="train_1000_stocks.pkl"
    )

    manager.close()
    
    # 3. åˆ›å»ºç¯å¢ƒ
    num_cpu = 20
    env = SubprocVecEnv([make_env(df_list, i, SEED) for i in range(num_cpu)])
    env = VecMonitor(env, LOG_DIR) # å¹¶è¡Œç‰ˆæ—¥å¿—ç›‘æ§
    # env = SimpleStockEnv(df_list)


    checkpoint_list = glob.glob("./checkpoints/sac_stock_auto_*.zip") # è·å–æ‰€æœ‰è‡ªåŠ¨ä¿å­˜çš„æ¨¡å‹
    os.makedirs(LOG_DIR, exist_ok=True)

    # 2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if os.path.exists(MODEL_PATH):
        print(f"ğŸ“¦ åŠ è½½ä¸»æ¨¡å‹: {MODEL_PATH}")
        load_path = MODEL_PATH
    elif checkpoint_list:
        # æ‰¾åˆ°ä¿®æ”¹æ—¶é—´æœ€æ™šï¼ˆæœ€æ–°ï¼‰çš„ä¸€ä¸ªå¤‡ä»½æ–‡ä»¶
        latest_checkpoint = max(checkpoint_list, key=os.path.getmtime)
        print(f"ğŸ”„ æœªå‘ç°ä¸»æ¨¡å‹ï¼Œæ­£åœ¨åŠ è½½æœ€æ–°å¤‡ä»½: {latest_checkpoint}")
        load_path = latest_checkpoint
    else:
        load_path = None

    if load_path:
        model = SAC.load(load_path, env=env, device="cuda")
    else:
        print("æœªå‘ç°å†å²æ¨¡å‹ï¼Œæ­£åœ¨åˆå§‹åŒ–æ–°æ¨¡å‹...")
        model = SAC(
            "MlpPolicy", 
            env, 
            tensorboard_log=LOG_DIR,
            learning_rate=3e-4, 
            buffer_size=1000000, 
            learning_starts=1000,
            batch_size=256,
            ent_coef='auto',
            target_entropy='auto',
            verbose=1,
            device="cuda"
        )

    # 3. è®¾ç½®è‡ªåŠ¨ä¿å­˜å›è°ƒï¼ˆé˜²æ­¢è®­ç»ƒä¸­é€”æ–­ç”µï¼‰
    # æ¯ 10,000 æ­¥ä¿å­˜ä¸€æ¬¡ï¼Œå­˜æ”¾åœ¨ ./checkpoints/ æ–‡ä»¶å¤¹ä¸‹
    checkpoint_callback = CheckpointCallback(
        save_freq=10000, 
        save_path='./checkpoints/',
        name_prefix='sac_stock_auto'
    )
    tb_callback = TensorboardCallback()
    callback_list = CallbackList([tb_callback, checkpoint_callback])
    # 4. å¼€å§‹/ç»§ç»­è®­ç»ƒ
    # reset_num_timesteps=False æ˜¯å…³é”®ï¼šå®ƒä¿è¯äº† Tensorboard æ›²çº¿å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨çš„è¿ç»­æ€§
    model.learn(
        total_timesteps=1000000, 
        callback=callback_list,
        reset_num_timesteps=False 
    )

    # 5. æ‰‹åŠ¨ä¿å­˜æœ€ç»ˆæ¨¡å‹
    model.save(MODEL_PATH)
    # 6. å…³é—­ç¯å¢ƒ
    env.close()